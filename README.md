# ğŸ’³ Credit Card Fraud Detection Pipeline - Real-time Streaming

**Äá»“ Ã¡n XLDLTT - HD10 | GV: Pháº¡m Minh TÃº | HCMUS**

---

## ğŸ“‹ Tá»•ng Quan

Há»‡ thá»‘ng xá»­ lÃ½ giao dá»‹ch tháº» tÃ­n dá»¥ng **REAL-TIME** vá»›i Kafka, Spark Streaming, Hadoop HDFS, Apache Airflow, vÃ  Power BI.

### TÃ­nh nÄƒng chÃ­nh:

âœ… **Stream Processing**: Kafka Producer stream data vá»›i delay 0.5-2s má»—i record (mÃ´ phá»ng real-time)
âœ… **Fraud Detection**: Spark Consumer lá»c giao dá»‹ch lá»—i vÃ  gian láº­n
âœ… **Currency Conversion**: Chuyá»ƒn Ä‘á»•i USD â†’ VND theo tá»‰ giÃ¡ VietcomBank
âœ… **Deduplication**: Loáº¡i bá» duplicate records trong streaming vá»›i watermark 24h
âœ… **Loop Mode**: Producer tá»± Ä‘á»™ng loop Ä‘á»ƒ stream liÃªn tá»¥c
âœ… **HDFS Storage**: LÆ°u trá»¯ phÃ¢n tÃ¡n, cÃ³ thá»ƒ scale
âœ… **Power BI Streaming**: Tá»± Ä‘á»™ng push data má»—i 5 phÃºt qua REST API
âœ… **Airflow Automation**: Workflow orchestration vá»›i schedule má»—i 5 phÃºt

---

## ğŸ—ï¸ Kiáº¿n TrÃºc Há»‡ Thá»‘ng

```
CSV File (19,964 records)
    â†“
Kafka Producer (delay 0.5-2s, LOOP mode)
    â†“
Kafka Topic: credit_card_transactions
    â†“
Spark Streaming Consumer
  â”œâ”€ Filter: Errors & Fraud
  â”œâ”€ Transform: USD â†’ VND
  â”œâ”€ Deduplication: Watermark 24h
  â””â”€ Enrich: Time features
    â†“
HDFS (/user/credit-pipeline/output/transactions)
    â†“
Airflow (schedule: */5 * * * *)
  â”œâ”€ Read new data from HDFS
  â”œâ”€ Export to CSV
  â”œâ”€ Push to Power BI Streaming Dataset (REST API)
  â””â”€ Track timestamp Ä‘á»ƒ trÃ¡nh duplicate
    â†“
Power BI Dashboard (Auto refresh)
```

---

## ğŸš€ HÆ°á»›ng Dáº«n Cháº¡y Há»‡ Thá»‘ng

### BÆ°á»›c 1: Clone Repository

```bash
git clone <repository-url>
cd XLPTDLTT---credit-card-fraud-detection-pipeline
```

### BÆ°á»›c 2: Táº¡o Power BI Streaming Dataset

1. VÃ o https://app.powerbi.com
2. Workspace â†’ **+ New** â†’ **Streaming dataset** â†’ **API**
3. Dataset name: `credit_transactions_realtime`
4. ThÃªm 15 fields:

| Field Name | Type |
|-----------|------|
| transaction_datetime | DateTime |
| Amount_USD | Number |
| Amount_VND | Number |
| Merchant_Name | Text |
| Merchant_City | Text |
| Merchant_State | Text |
| MCC | Number |
| Is_Fraud | Text |
| transaction_type | Text |
| day_of_week | Number |
| transaction_year | Number |
| transaction_month | Number |
| transaction_hour | Number |
| User | Number |
| Card | Number |

5. âœ… TÃ­ch **Historic data analysis**
6. Click **Create** â†’ **Copy Push URL**

### BÆ°á»›c 3: Cáº¥u hÃ¬nh .env

Táº¡o file `.env` trong thÆ° má»¥c gá»‘c:

```env
# Power BI Streaming Dataset Push URL
POWERBI_STREAMING_URL=https://api.powerbi.com/beta/.../datasets/.../rows?key=...

# Optional: Override default settings
KAFKA_BROKER=kafka:9092
```

### BÆ°á»›c 4: Khá»Ÿi Ä‘á»™ng Docker

```bash
# Build vÃ  start táº¥t cáº£ services
docker-compose build
docker-compose up -d

# Äá»£i 60-90 giÃ¢y Ä‘á»ƒ services khá»Ÿi Ä‘á»™ng
```

### BÆ°á»›c 5: Kiá»ƒm tra Logs

```bash
# Kafka Producer (stream data)
docker logs -f credit-producer

# Spark Consumer (xá»­ lÃ½ & lÆ°u HDFS)
docker logs -f credit-consumer

# Airflow (push lÃªn Power BI)
docker logs -f airflow
```

### BÆ°á»›c 6: VÃ o Airflow UI

```
URL: http://localhost:8080
Username: admin
Password: admin
```

**Kiá»ƒm tra:**
- DAG `powerbi_streaming_upload` pháº£i **ON** (mÃ u xanh)
- Sau 5 phÃºt, xem **Runs** cÃ³ thÃ nh cÃ´ng khÃ´ng

### BÆ°á»›c 7: Kiá»ƒm tra Power BI

VÃ o https://app.powerbi.com â†’ Workspace â†’ Dataset

Refresh trang (F5) â†’ Tháº¥y sá»‘ lÆ°á»£ng rows tÄƒng dáº§n má»—i 5 phÃºt!

---

## ğŸ“Š Timeline Demo (30 phÃºt)

| Thá»i gian | Producer Streamed | HDFS | Airflow Push | Power BI Rows |
|-----------|------------------|------|--------------|---------------|
| T+0 | 0 | 0 | - | 0 |
| T+5 phÃºt | ~150-600 | ~150-600 | Láº§n 1 âœ… | ~150-600 |
| T+10 phÃºt | ~300-1,200 | ~300-1,200 | Láº§n 2 âœ… | ~300-1,200 |
| T+15 phÃºt | ~450-1,800 | ~450-1,800 | Láº§n 3 âœ… | ~450-1,800 |
| T+30 phÃºt | ~900-3,600 | ~900-3,600 | Láº§n 7 âœ… | ~900-3,600 |

**Delay:** 0.5-2s má»—i record â†’ Trong 30 phÃºt cÃ³ ~900-3,600 records

---

## ğŸ›‘ Táº¡m dá»«ng & Tiáº¿p tá»¥c

### Ngá»«ng há»‡ thá»‘ng (giá»¯ data):

```bash
docker-compose stop
```

### Cháº¡y tiáº¿p mai:

```bash
docker-compose start
```

### Reset hoÃ n toÃ n (xÃ³a táº¥t cáº£ data):

```bash
# XÃ³a tracking file trÃªn host
del powerbi_exports\last_push_timestamp.txt

# Reset HDFS (cáº§n containers Ä‘ang cháº¡y)
docker exec namenode hdfs dfs -rm -r /user/credit-pipeline/output/transactions
docker exec namenode hdfs dfs -rm -r /user/credit-pipeline/checkpoints

# Hoáº·c reset hoÃ n toÃ n
docker-compose down -v
docker-compose build
docker-compose up -d
```

---

## ğŸ“ Cáº¥u TrÃºc ThÆ° Má»¥c

```
XLPTDLTT---credit-card-fraud-detection-pipeline/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ kafka_producer.py              # Producer (loop mode, 0.5-2s delay)
â”‚   â”œâ”€â”€ spark_streaming_consumer.py    # Consumer (deduplication, watermark 24h)
â”‚   â””â”€â”€ exchange_rate_scraper.py       # VietcomBank rate scraper
â”‚
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ powerbi_streaming_dag.py       # Airflow DAG (schedule: */5 * * * *)
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ reset_hdfs.cmd                 # Script xÃ³a data cÅ© trong HDFS
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ User0_credit_card_transactions.csv  # 19,964 records
â”‚
â”œâ”€â”€ powerbi_exports/                   # CSV táº¡m & tracking file
â”‚   â”œâ”€â”€ all_transactions.csv
â”‚   â””â”€â”€ last_push_timestamp.txt
â”‚
â”œâ”€â”€ docker-compose.yml                 # Docker orchestration
â”œâ”€â”€ Dockerfile.airflow                 # Custom Airflow vá»›i Java
â”œâ”€â”€ .env                               # Power BI Streaming URL
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md                          # File nÃ y
â””â”€â”€ HUONG_DAN_DEMO_REALTIME.md        # HÆ°á»›ng dáº«n demo chi tiáº¿t
```

---

## ğŸ”§ CÃ¡c TÃ­nh NÄƒng Ká»¹ Thuáº­t

### 1. Loop Mode (Producer)

Producer tá»± Ä‘á»™ng loop khi stream háº¿t 19,964 records:

```python
# kafka_producer.py:52-111
while True:
    loop_iteration += 1
    # Stream all records
    for row in csv_reader:
        # Loop 2+: Update timestamp to NOW
        if loop_iteration > 1:
            row["Year"] = str(now.year)
            row["Month"] = str(now.month)
            # ...
        time.sleep(random.uniform(0.5, 2))

    # Restart after 5s
    time.sleep(5)
```

### 2. Deduplication (Spark Consumer)

Loáº¡i bá» duplicate dá»±a trÃªn unique key:

```python
# spark_streaming_consumer.py:194-202
df_watermarked = df_filtered.withWatermark("transaction_datetime", "24 hours")
df_deduplicated = df_watermarked.dropDuplicates([
    "transaction_datetime", "User", "Card", "Amount_USD"
])
```

### 3. Timestamp Tracking (Airflow)

Chá»‰ push records má»›i, trÃ¡nh duplicate trÃªn Power BI:

```python
# powerbi_streaming_dag.py:58-74
tracking_file = "/app/powerbi_exports/last_push_timestamp.txt"
if os.path.exists(tracking_file):
    last_timestamp = f.read().strip()
    df = df.filter(col('transaction_datetime') > last_timestamp)

# After push:
max_timestamp = df_filtered['transaction_datetime'].max()
with open(tracking_file, 'w') as f:
    f.write(str(max_timestamp))
```

### 4. Auto-restart (Docker Compose)

Producer vÃ  Consumer tá»± Ä‘á»™ng restart khi crash:

```yaml
# docker-compose.yml:56,68
producer:
  restart: unless-stopped

consumer:
  restart: unless-stopped
```

---

## â“ Troubleshooting

### 1. Producer khÃ´ng stream

```bash
docker logs credit-producer
# Náº¿u bÃ¡o "CSV file not found" â†’ Kiá»ƒm tra data/User0_credit_card_transactions.csv
```

### 2. Airflow bÃ¡o "No new data"

XÃ³a tracking file:

```bash
docker exec airflow rm -f /app/powerbi_exports/last_push_timestamp.txt
docker exec airflow airflow dags trigger powerbi_streaming_upload
```

### 3. Power BI bÃ¡o 404 Not Found

URL sai hoáº·c dataset bá»‹ xÃ³a:

1. Táº¡o láº¡i dataset trÃªn Power BI
2. Copy URL má»›i
3. Update `.env`
4. `docker-compose down && docker-compose up -d`

### 4. HDFS Connection Failed

```bash
docker exec namenode hdfs dfsadmin -report
# Náº¿u safe mode: hdfs dfsadmin -safemode leave
```

### 5. Power BI khÃ´ng auto-refresh

Dashboard cáº§n báº­t auto-refresh:

1. Má»Ÿ Dashboard trÃªn Power BI Web
2. Settings â†’ Refresh interval â†’ Set **1 minute**
3. Hoáº·c báº¥m F5 thá»§ cÃ´ng má»—i 5 phÃºt

---

## ğŸ“ˆ 10 CÃ¢u Há»i NghiÃªn Cá»©u

Dashboard Power BI tráº£ lá»i cÃ¡c cÃ¢u há»i sau dá»±a trÃªn 15 fields:

1. **Thá»i Ä‘iá»ƒm nÃ o trong ngÃ y cÃ³ nhiá»u giao dá»‹ch?** â†’ `transaction_hour`
2. **ThÃ nh phá»‘ nÃ o cÃ³ tá»•ng giÃ¡ trá»‹ cao nháº¥t?** â†’ `Merchant_City`, `Amount_VND`
3. **Merchant nÃ o cÃ³ nhiá»u giao dá»‹ch nháº¥t?** â†’ `Merchant_Name`
4. **Tá»· lá»‡ fraud theo Ä‘á»‹a Ä‘iá»ƒm?** â†’ `Is_Fraud`, `Merchant_City`
5. **User nÃ o cÃ³ nhiá»u giao dá»‹ch liÃªn tiáº¿p?** â†’ `User`, `transaction_datetime`
6. **Giao dá»‹ch giÃ¡ trá»‹ lá»›n á»Ÿ Ä‘Ã¢u?** â†’ `Amount_USD > 500`, `Merchant_City`
7. **Xu hÆ°á»›ng fraud theo thá»i gian?** â†’ `Is_Fraud`, `transaction_year`, `transaction_month`
8. **KhÃ¡c biá»‡t ngÃ y thÆ°á»ng vs cuá»‘i tuáº§n?** â†’ `day_of_week`, `transaction_type`
9. **User nÃ o cÃ³ nhiá»u fraud?** â†’ `User`, `Is_Fraud`
10. **Äá» xuáº¥t cáº£i tiáº¿n há»‡ thá»‘ng?** â†’ Recommendations tá»« phÃ¢n tÃ­ch

---

## ğŸ¯ Káº¿t Quáº£ Mong Äá»£i

### Real-time Processing:
- âœ… Kafka stream 0.5-2s/record
- âœ… Spark process real-time
- âœ… Filter fraud & errors
- âœ… Deduplication with watermark
- âœ… USD â†’ VND conversion
- âœ… Save to HDFS

### Power BI Integration:
- âœ… Airflow schedule má»—i 5 phÃºt
- âœ… Auto push new data via REST API
- âœ… Timestamp tracking (no duplicate)
- âœ… Dashboard auto-refresh
- âœ… 15 fields cho phÃ¢n tÃ­ch Ä‘áº§y Ä‘á»§

### Demo:
- âœ… Dashboard tÄƒng tá»« 0 â†’ 900-3,600 rows trong 30 phÃºt
- âœ… Real-time growth visualization
- âœ… Tráº£ lá»i Ä‘Æ°á»£c 10 cÃ¢u há»i nghiÃªn cá»©u

---

## ğŸ“š TÃ i Liá»‡u Tham Kháº£o

- [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
- [Spark Structured Streaming](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)
- [Hadoop HDFS](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html)
- [Apache Airflow](https://airflow.apache.org/docs/)
- [Power BI Streaming Dataset](https://learn.microsoft.com/en-us/power-bi/connect-data/service-real-time-streaming)

---

## ğŸ“ Ghi ChÃº Quan Trá»ng

### Vá» Deduplication:
- Spark watermark chá»‰ nhá»› **24 giá»**
- Náº¿u Producer loop sau >24h, cÃ³ thá»ƒ cÃ³ duplicate (hiáº¿m)
- Äá»‘i vá»›i demo, 24h lÃ  Ä‘á»§

### Vá» Tracking File:
- File `/app/powerbi_exports/last_push_timestamp.txt` náº±m trong **bind-mount volume**
- `docker-compose down -v` **KHÃ”NG XÃ“A** file nÃ y
- Pháº£i xÃ³a thá»§ cÃ´ng trÃªn host náº¿u muá»‘n reset

### Vá» Power BI Refresh:
- Power BI **KHÃ”NG Tá»° Äá»˜NG refresh** trÃªn browser
- Cáº§n báº¥m F5 hoáº·c báº­t auto-refresh 1 phÃºt trong settings
- Backend Ä‘Ã£ nháº­n data ngay láº­p tá»©c

---

## ğŸ“ Credits

**Äá»“ Ã¡n:** CSC17106 - Xá»­ LÃ½ PhÃ¢n TÃ­ch Dá»¯ Liá»‡u Trá»±c Tuyáº¿n
**Giáº£ng viÃªn:** Pháº¡m Minh TÃº
**TrÆ°á»ng:** Äáº¡i há»c Khoa há»c Tá»± nhiÃªn - ÄHQG TP.HCM

---
